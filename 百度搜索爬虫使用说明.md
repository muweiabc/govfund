# 百度搜索爬虫使用说明

## 概述
这个项目包含两个爬虫脚本，都可以在百度搜索"专利"并提取搜索结果：
1. `patent_scraper.py` - 修改后的专利爬虫（现在用于百度搜索）
2. `baidu_scraper.py` - 专门为百度搜索创建的爬虫

## 功能特性
- ✅ 自动访问百度首页
- ✅ 在搜索框输入"专利"关键词
- ✅ 自动点击搜索按钮
- ✅ 提取前20个搜索结果
- ✅ 保存结果到Excel文件
- ✅ 禁用JavaScript debugger，避免渲染暂停
- ✅ 反自动化检测

## 使用方法

### 方法1: 使用专门的百度爬虫（推荐）
```bash
python baidu_scraper.py
```

### 方法2: 使用修改后的专利爬虫
```bash
python patent_scraper.py
```

## 输出结果

### 控制台输出
程序运行时会显示：
- 浏览器初始化状态
- 搜索过程
- 提取结果数量
- 前5个结果的详细信息

### Excel文件输出
结果会保存到 `baidu_search_results.xlsx` 文件，包含以下字段：
- `title`: 搜索结果标题
- `link`: 链接地址
- `abstract`: 搜索结果摘要
- `source`: 来源信息
- `time`: 时间信息

## 技术特点

### 反检测机制
```python
# 禁用自动化标识
chrome_options.add_argument("--disable-blink-features=AutomationControlled")
chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
chrome_options.add_experimental_option('useAutomationExtension', False)

# 禁用debugger
chrome_options.add_argument("--disable-javascript-debugger")
self.driver.execute_cdp_cmd("Debugger.setBreakpointsActive", {"active": False})
```

### 智能元素定位
- 使用多种CSS选择器确保元素能被找到
- 等待元素加载完成后再操作
- 错误处理和重试机制

## 配置选项

### 搜索参数
- 关键词：默认搜索"专利"
- 结果数量：限制为前20个
- 等待时间：页面加载等待3秒

### 浏览器配置
- 窗口大小：1920x1080
- 用户代理：模拟真实浏览器
- 禁用图片和插件（可选）

## 自定义搜索

### 修改搜索关键词
在代码中修改 `keyword` 变量：
```python
keyword = "你的搜索关键词"  # 替换"专利"
```

### 修改结果数量
在 `extract_baidu_results` 方法中修改：
```python
for i, element in enumerate(result_elements[:50]):  # 改为50个结果
```

## 故障排除

### 常见问题

#### 1. ChromeDriver初始化失败
**解决方案**：运行修复脚本
```bash
python fix_chromedriver.py
```

#### 2. 找不到搜索元素
**可能原因**：百度页面结构变化
**解决方案**：检查CSS选择器，更新选择器

#### 3. 搜索结果为空
**可能原因**：网络问题或页面加载不完整
**解决方案**：增加等待时间，检查网络连接

### 调试技巧

#### 启用详细日志
在代码中添加更多print语句：
```python
print(f"当前页面标题: {self.driver.title}")
print(f"当前页面URL: {self.driver.current_url}")
```

#### 保存页面源码
```python
with open("page_source.html", "w", encoding="utf-8") as f:
    f.write(self.driver.page_source)
```

## 性能优化

### 减少等待时间
```python
# 减少不必要的等待
time.sleep(2)  # 从3秒改为2秒
```

### 启用无头模式
```python
chrome_options.add_argument("--headless")  # 不显示浏览器窗口
```

### 禁用图片加载
```python
chrome_options.add_argument("--disable-images")  # 提高加载速度
```

## 注意事项

### 使用限制
- 请遵守百度的使用条款
- 不要过于频繁地发送请求
- 建议在非高峰时段使用

### 法律合规
- 仅用于学习和研究目的
- 不要用于商业用途
- 遵守相关法律法规

### 技术限制
- 依赖Chrome浏览器
- 需要稳定的网络连接
- 可能受到百度反爬虫机制影响

## 扩展功能

### 批量搜索
可以修改代码支持多个关键词：
```python
keywords = ["专利", "知识产权", "发明专利"]
for keyword in keywords:
    results = scraper.search_baidu(keyword)
    # 处理结果
```

### 多页面爬取
可以添加翻页功能：
```python
# 查找下一页按钮
next_button = self.driver.find_element(By.CSS_SELECTOR, ".n")
next_button.click()
```

### 数据过滤
可以添加结果过滤功能：
```python
# 过滤包含特定关键词的结果
filtered_results = [r for r in results if "专利" in r.get("title", "")]
```

## 联系支持

如果遇到问题：
1. 检查Chrome浏览器版本
2. 运行 `python fix_chromedriver.py`
3. 查看控制台错误信息
4. 提供具体的错误描述

## 更新日志

- **v1.0**: 初始版本，支持基本搜索功能
- **v1.1**: 添加反检测机制
- **v1.2**: 优化元素定位策略
- **v1.3**: 添加debugger禁用功能
